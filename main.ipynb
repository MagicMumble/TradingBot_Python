{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import tulipy as ti\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forex_data = yf.download('EURUSD=X', start='2019-01-02', end='2021-12-31')\n",
    "forex_data.index = pd.to_datetime(forex_data.index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecee732f95cbda8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forex_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48582fb61155e9d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forex_data.iloc[1:,:].head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a195b9a43e6e747e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the close price\n",
    "plt.figure(figsize=(15, 7))\n",
    "forex_data['Adj Close'].plot()\n",
    "\n",
    "# Set the title and axis label\n",
    "plt.title('EUR/USD Data', fontsize=16)\n",
    "plt.xlabel('Year-Month', fontsize=15)\n",
    "plt.ylabel('Price', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.legend(['Close'], prop={'size': 15})\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6055595cd3aa1535"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the ticker as 'EURUSD=X'\n",
    "forex_data_minute = yf.download('EURUSD=X', period='7d', interval='1m')\n",
    "\n",
    "# Set the index to a datetime object\n",
    "forex_data_minute.index = pd.to_datetime(forex_data_minute.index)\n",
    "\n",
    "# Display the last five rows\n",
    "forex_data_minute.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e1a6431de35bdb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Labeling(data, windowSize):\n",
    "    closePriceList = data['Adj Close'].values.tolist()\n",
    "    counterRow, numberOfDaysInFile = 0, len(closePriceList)\n",
    "    zeros_at_the_beginning = windowSize // 2\n",
    "    labels = np.empty(zeros_at_the_beginning)\n",
    "    labels.fill(np.nan)\n",
    "    labels = labels.tolist()\n",
    "    while counterRow < numberOfDaysInFile:\n",
    "        min, max = math.inf, -math.inf\n",
    "        counterRow += 1\n",
    "        maxIndex, minIndex = -1, -1\n",
    "        if counterRow >= windowSize:\n",
    "            windowBeginIndex = counterRow - windowSize\n",
    "            windowEndIndex = windowBeginIndex + windowSize - 1\n",
    "            windowMiddleIndex = (windowBeginIndex + windowEndIndex) // 2\n",
    "            for i in range(windowBeginIndex, windowEndIndex + 1):\n",
    "                number = closePriceList[i]\n",
    "                if number < min:\n",
    "                    min = number\n",
    "                    minIndex = i\n",
    "                if number > max:\n",
    "                    max = number\n",
    "                    maxIndex = i\n",
    "            if maxIndex == windowMiddleIndex:\n",
    "                # labels.append(\"SELL\")\n",
    "                labels.append(2)\n",
    "            elif minIndex == windowMiddleIndex:\n",
    "                # labels.append(\"BUY\")\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                # labels.append(\"HOLD\")\n",
    "                labels.append(0)\n",
    "\n",
    "    zeros = np.empty(windowSize - zeros_at_the_beginning - 1)\n",
    "    zeros.fill(np.nan)\n",
    "    labels = np.append(labels, zeros.tolist())\n",
    "    new_data = data.copy()\n",
    "    new_data['Labels'] = labels\n",
    "    return new_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c769c4b6e49d18b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forex_data_minute = Labeling(forex_data_minute, 5)\n",
    "forex_data_minute.head(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da4d294105540b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ti_sma(period, data):\n",
    "    res = ti.sma(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'SMA_{period}'] = add_nans(period - 1, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_ema(period, data):\n",
    "    res = ti.ema(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'EMA_{period}'] = res\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_hma(period, data):\n",
    "    res = ti.hma(data['Close'].values, period=period)\n",
    "    if period <= 8:\n",
    "        change = 0\n",
    "    elif period <= 15:\n",
    "        change = 1\n",
    "    elif period <= 24:\n",
    "        change = 2\n",
    "    else:\n",
    "        change = 3\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'HMA_{period}'] = add_nans(period + change, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_wma(period, data):\n",
    "    res = ti.wma(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'WMA_{period}'] = add_nans(period - 1, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_triple_ema(period, data):\n",
    "    res = ti.tema(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'T_EMA_{period}'] = add_nans(period * 3 - 3, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def add_nans(period, res):\n",
    "    a = np.empty(period)\n",
    "    a.fill(np.nan)\n",
    "    return np.append(a, res)\n",
    "\n",
    "\n",
    "def ti_willr(period, data):\n",
    "    res = ti.willr(data['High'].values, data['Low'].values, data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'WILLR_{period}'] = add_nans(period - 1, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_rsi(period, data):\n",
    "    res = ti.rsi(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'RSI_{period}'] = add_nans(period, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_cci(period, data):\n",
    "    res = ti.cci(data['High'].values, data['Low'].values, data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'CCI_{period}'] = add_nans(period + period - 2, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_cmo(period, data):\n",
    "    res = ti.cmo(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'CMO_{period}'] = add_nans(period, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_roc(period, data):\n",
    "    res = ti.roc(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'ROC_{period}'] = add_nans(period, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "# extra indicator for firex data to make the image of size 15x15\n",
    "def ti_kama(period, data):\n",
    "    res = ti.kama(data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'KAMA_{period}'] = add_nans(period - 1, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_dmi(period, data):\n",
    "    res = ti.dx(data['High'].values, data['Low'].values, data['Close'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'DMI_{period}'] = add_nans(period - 1, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def get_periods(period):\n",
    "    return period, period * 2, int(0.75 * period)\n",
    "\n",
    "\n",
    "def ti_macd(period, data):\n",
    "    shortTermEma = ti.ema(data['Close'].values, period=period)\n",
    "    longTermEma = ti.ema(data['Close'].values, period=period * 2)\n",
    "    res = shortTermEma - longTermEma\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'MACD_{period}'] = res\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_ppo(period, data):\n",
    "    short_period, long_period, _ = get_periods(period)\n",
    "    res = ti.ppo(data['Close'].values, short_period, long_period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'PPO_{period}'] = add_nans(1, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "# etfs have volumes, forex data doesn't, for the forex data we use kama indicator instead\n",
    "def ti_cmfi(period, data):\n",
    "    res = ti.mfi(data['High'].values, data['Low'].values, data['Close'].values, data['Volume'].values, period=period)\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'CMFI_{period}'] = add_nans(period, res)\n",
    "    return newFrame\n",
    "\n",
    "\n",
    "def ti_psar(period, data):\n",
    "    res, data_high, data_low = [np.NAN], data['High'].values, data['Low'].values\n",
    "    for i in range(1, len(data)):\n",
    "        start = max(0, i - period + 1)\n",
    "        res.append(ti.psar(data_high[start:i + 1], data_low[start:i + 1], 0.02, 0.2)[-1])\n",
    "    newFrame = data.copy()\n",
    "    newFrame[f'PSAR_{period}'] = res\n",
    "    return newFrame"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b00ac55b112e16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forex_data_minute = ti_psar(5, forex_data_minute)\n",
    "forex_data_minute"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2138298e7d0a2a69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# there is no volume records for forex data, so we skip this step\n",
    "def adjust_the_prices(data):\n",
    "    data['Open'] = (data['Open'] * data['Volume']) / data['Adj Close']\n",
    "    data['High'] = (data['High'] * data['Volume']) / data['Adj Close']\n",
    "    data['Low'] = (data['Low'] * data['Volume']) / data['Adj Close']\n",
    "    # data.rename(columns={\"Adj Close\": \"Close\"}, inplace=True)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbb6024f379064e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_data(directory, ticket, forex):\n",
    "    datas = []\n",
    "    for file in sorted(os.listdir(directory)):\n",
    "        if ticket in file:\n",
    "            data = pd.read_csv(os.path.join(directory, file), index_col=['Datetime'])\n",
    "            data.index = pd.to_datetime(data.index)\n",
    "            print('read file - ', file, 'len = ', len(data))\n",
    "            print('len data before = ', len(data))\n",
    "            data = create_data(data, forex)\n",
    "            print('len data after2 = ', len(data))\n",
    "            datas.append(data)\n",
    "    data = datas[0]\n",
    "    for i in range(1, len(datas)):\n",
    "        data = data.append(datas[i])\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f04893e0380a66d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def create_data(data, forex=True):\n",
    "    if not forex:\n",
    "        data = adjust_the_prices(data)\n",
    "\n",
    "    # label the data: BUY(1), SELL(2), HOLD(0)\n",
    "    data = data.astype('float64')\n",
    "    data = Labeling(data, 11)\n",
    "\n",
    "    # order of indicators matters\n",
    "    eft_indicators = [ti_rsi, ti_willr, ti_wma, ti_ema, ti_sma, ti_hma, ti_triple_ema, ti_cci, ti_cmo, ti_macd, ti_ppo,\n",
    "                      ti_roc, ti_cmfi, ti_dmi, ti_psar]\n",
    "\n",
    "    forex_indicators = [ti_rsi, ti_willr, ti_wma, ti_ema, ti_sma, ti_kama, ti_hma, ti_triple_ema, ti_cci, ti_cmo,\n",
    "                        ti_macd, ti_ppo, ti_roc, ti_dmi, ti_psar]\n",
    "\n",
    "    for period in range(5, 20):\n",
    "        if forex:\n",
    "            indicators = forex_indicators\n",
    "        else:\n",
    "            indicators = eft_indicators\n",
    "        for indicator in indicators:\n",
    "            data = indicator(period, data)\n",
    "\n",
    "    # do not remove 'Adj Close'\n",
    "    data.drop(labels=[\"Volume\", \"Low\", \"High\", \"Open\", \"Close\"], axis=1, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # TODO: round TA indicators up to 2 values after the point after normalization?? (according to the article)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d4c65eaa209d77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data = read_data('./historical_data/forex_minutes/', 'EURUSD=X', forex=True)\n",
    "data = read_data('./historical_data/etfs_minutes/', 'EWH', forex=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cafc0f4e6fd74cbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac3d7e021da24c64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_to_csv():\n",
    "    start = ['2023-08-20', '2023-08-27', '2023-09-03', '2023-09-10']\n",
    "    end = ['2023-08-27', '2023-09-03', '2023-09-10', '2023-09-17']\n",
    "    currencies = ['EURUSD=X', 'EURTRY=X', 'EURRUB=X', 'ARSUSD=X', 'AUDUSD=X', 'JPYUSD=X', 'IRRUSD=X', 'KPW=X',\n",
    "                  'EURDKK=X', 'SEKUSD=X']\n",
    "    etfs = ['XLF', 'QQQ', 'SPY', 'XLP', 'EWZ', 'EWH', 'XLY', 'XLE']\n",
    "    files = os.listdir('./historical_data/forex_minutes') + (os.listdir('./historical_data/etfs_minutes'))\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(len(currencies)):\n",
    "            file_name = f'{start[i]}_to_{end[i]}_{currencies[j]}.csv'\n",
    "            if file_name not in files:\n",
    "                data = yf.download(currencies[j], start=start[i], end=end[i], interval='1m')\n",
    "                if len(data) > 0:\n",
    "                    data.to_csv('historical_data/forex_minutes/' + file_name)\n",
    "            else:\n",
    "                print('already exists: ', file_name)\n",
    "        for j in range(len(etfs)):\n",
    "            file_name = f'{start[i]}_to_{end[i]}_{etfs[j]}.csv'\n",
    "            if file_name not in files:\n",
    "                data = yf.download(etfs[j], start=start[i], end=end[i], interval='1m')\n",
    "                if len(data) > 0:\n",
    "                    data.to_csv('historical_data/etfs_minutes/' + file_name)\n",
    "            else:\n",
    "                print('already exists: ', file_name)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41b99021a7ff4fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_to_csv()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6925b74c9f08a3ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "def normalize(data):\n",
    "    scaler = MinMaxScaler((-1, 1))\n",
    "    data_to_normalize = data.drop(labels=[\"Labels\", \"Adj Close\"], axis=1)\n",
    "    columns = data_to_normalize.columns\n",
    "    data_scaled = scaler.fit_transform(data_to_normalize.to_numpy())\n",
    "    joblib.dump(scaler, 'prediction_tools/TCSG_minutes_scaler.sav')\n",
    "    # index gets removed, columns are also not needed, might be removed too\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns=columns)\n",
    "    data_scaled['Adj Close'] = data['Adj Close'].values\n",
    "    data_scaled['Labels'] = data['Labels'].values\n",
    "    return data_scaled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c469fa99d59a64b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized_data = normalize(data)\n",
    "normalized_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f111535f978516e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_loaded_scaler(data):\n",
    "    scaler = joblib.load('prediction_tools/TCSG_minutes_scaler_testing.sav')\n",
    "    data_to_normalize = data.drop(labels=[\"Labels\", \"Adj Close\"], axis=1)\n",
    "    columns = data_to_normalize.columns\n",
    "    data_scaled = scaler.fit_transform(data_to_normalize.to_numpy())\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns=columns)\n",
    "    data_scaled['Adj Close'] = data['Adj Close'].values\n",
    "    data_scaled['Labels'] = data['Labels'].values\n",
    "    return data_scaled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6f1dbaa9e0096c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized_data = test_loaded_scaler(data)\n",
    "normalized_data.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c84801b5df32f81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: split into training and test sets\n",
    "# 4 weeks altogether, let's split into 3/1\n",
    "\n",
    "training_proportion = int(0.75 * len(normalized_data))\n",
    "training_set = normalized_data[:training_proportion]\n",
    "testing_set = normalized_data[training_proportion:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90ec54fe5cafceab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def solve_imbalance_problem(data):\n",
    "    data = data.iloc[15:, :]\n",
    "\n",
    "    l0_train = data.loc[data['Labels'] == 0]\n",
    "    l1_train = data.loc[data['Labels'] == 1]\n",
    "    l2_train = data.loc[data['Labels'] == 2]\n",
    "    l0_size = l0_train.shape[0]\n",
    "    l1_size = l1_train.shape[0]\n",
    "    l2_size = l2_train.shape[0]\n",
    "\n",
    "    l0_l1_ratio = (l0_size // l1_size)\n",
    "    l0_l2_ratio = (l0_size // l2_size)\n",
    "    print(\"Before\")\n",
    "    print(\"l0_size:\", l0_size, \"l1_size:\", l1_size, \"l2_size:\", l2_size)\n",
    "    print(\"l0_l1_ratio:\", l0_l1_ratio, \"l0_l2_ratio:\", l0_l2_ratio)\n",
    "\n",
    "    l1_new = pd.DataFrame()\n",
    "    l2_new = pd.DataFrame()\n",
    "    for idx, row in data.iterrows():\n",
    "        if row['Labels'] == 1:\n",
    "            for i in range(l0_l1_ratio):\n",
    "                l1_new = l1_new.append(row)\n",
    "        if row['Labels'] == 2:\n",
    "            for i in range(l0_l2_ratio):\n",
    "                l2_new = l2_new.append(row)\n",
    "\n",
    "    data = data.append(l1_new)\n",
    "    data = data.append(l2_new)\n",
    "\n",
    "    # shuffle\n",
    "    data = shuffle(data)\n",
    "\n",
    "    ########################################################\n",
    "    l0_train = data.loc[data['Labels'] == 0]\n",
    "    l1_train = data.loc[data['Labels'] == 1]\n",
    "    l2_train = data.loc[data['Labels'] == 2]\n",
    "    l0_size = l0_train.shape[0]\n",
    "    l1_size = l1_train.shape[0]\n",
    "    l2_size = l2_train.shape[0]\n",
    "\n",
    "    l0_l1_ratio = (l0_size // l1_size)\n",
    "    l0_l2_ratio = (l0_size // l2_size)\n",
    "    print(\"After\")\n",
    "    print(\"l0_size:\", l0_size, \"l1_size:\", l1_size, \"l2_size:\", l2_size)\n",
    "    print(\"l0_l1_ratio:\", l0_l1_ratio, \"l0_l2_ratio:\", l0_l2_ratio)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99097fbca67eb6cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# only for training set\n",
    "training_set = solve_imbalance_problem(training_set)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28219fc099545d3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "\n",
    "\n",
    "def reverse_one_hot(predictions):\n",
    "    reversed_x = []\n",
    "    for x in predictions:\n",
    "        reversed_x.append(np.argmax(np.array(x)))\n",
    "    return reversed_x\n",
    "\n",
    "\n",
    "def train_cnn(training_df, test_df, params):\n",
    "    \"\"\"Trains and evaluates CNN on the given train and test data, respectively.\"\"\"\n",
    "\n",
    "    print(\"Training is starting ...\")\n",
    "    train_images = np.array(training_df.iloc[:, :-2].values.tolist())\n",
    "    train_labels = training_df['Labels']\n",
    "    train_prices = training_df['Adj Close']\n",
    "\n",
    "    test_images = np.array((test_df.iloc[:, :-2].values.tolist()))\n",
    "    test_labels = test_df['Labels']\n",
    "    test_prices = test_df['Adj Close']\n",
    "\n",
    "    test_labels = keras.utils.to_categorical(test_labels, params[\"num_classes\"])\n",
    "    train_labels = keras.utils.to_categorical(train_labels, params[\"num_classes\"])\n",
    "\n",
    "    train_images = train_images.reshape(train_images.shape[0], params[\"input_w\"], params[\"input_h\"], 1)\n",
    "    test_images = test_images.reshape(test_images.shape[0], params[\"input_w\"], params[\"input_h\"], 1)\n",
    "\n",
    "    # CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(params[\"input_w\"], params[\"input_h\"], 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(params[\"num_classes\"], activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy', 'mae', 'mse'])\n",
    "\n",
    "    train_data_size = train_images.shape[0]\n",
    "    test_data_size = test_images.shape[0]\n",
    "\n",
    "    print(\"model will be trained with {} and be tested with {} sample\".format(train_data_size, test_data_size))\n",
    "    # fit the model to the training data\n",
    "    print(\"Fitting model to the training data...\")\n",
    "    print(\"\")\n",
    "    model.fit(train_images, train_labels, batch_size=params[\"batch_size\"], epochs=params[\"epochs\"], verbose=1,\n",
    "              validation_data=None)\n",
    "\n",
    "    predictions = model.predict(test_images, batch_size=params[\"batch_size\"], verbose=1)\n",
    "    print(model.evaluate(test_images, test_labels, batch_size=params[\"batch_size\"], verbose=1))\n",
    "\n",
    "    print(\"Train conf matrix: \", confusion_matrix(np.array(reverse_one_hot(train_labels)),\n",
    "                                                  np.array(reverse_one_hot(\n",
    "                                                      model.predict(train_images, batch_size=params[\"batch_size\"],\n",
    "                                                                    verbose=1)))))\n",
    "\n",
    "    print(\"Test conf matrix: \", confusion_matrix(np.array(reverse_one_hot(test_labels)),\n",
    "                                                 np.array(reverse_one_hot(predictions))))\n",
    "\n",
    "    return predictions, test_labels, test_prices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d557dc357afcb226"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"train_df size: \", training_set.shape)\n",
    "\n",
    "# TODO: should round values to two values after point??\n",
    "\n",
    "# fill params dict before call train_cnn\n",
    "params = {\"input_w\": 15, \"input_h\": 15, \"num_classes\": 3, \"batch_size\": 1024, \"epochs\": 200}\n",
    "#params = {\"input_w\": 15, \"input_h\": 15, \"num_classes\": 3, \"batch_size\": 1024, \"epochs\": 100}\n",
    "training_set.reset_index(drop=True, inplace=True)\n",
    "testing_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "predictions, test_labels, test_prices = train_cnn(training_set, testing_set, params)\n",
    "\n",
    "result_df = pd.DataFrame({\"prediction\": np.argmax(predictions, axis=1),\n",
    "                          \"test_label\": np.argmax(test_labels, axis=1),\n",
    "                          \"test_price\": test_prices})\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e72bacaf56c17bfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f651908502d7592"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(result_df['test_label'], result_df['prediction']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4cdb37c047ad114"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(result_df['test_label'], result_df['prediction']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a92acf075c0fd22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Precision means the percentage of correct positive predictions relative to total positive predictions. Recall reflects percentage of correct positive predictions relative to total actual positives. F1 Score represents weighted harmonic mean of precision and recall. The closer it is to 1, the better the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6932e9dd98e7ece6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 10000 - starting capital in certain currency\n",
    "def calculate_profit(money, predictions, prices):\n",
    "    # TODO: have to consider transaction fee and number of transactions\n",
    "    transactions_count = 0\n",
    "    last_sell = len(predictions) - predictions[::-1].index(2) - 1  # find last Sell label\n",
    "    first_buy = predictions.index(1)  #find first buy\n",
    "    predictions = predictions[first_buy:last_sell + 1]\n",
    "    prices = prices[first_buy:last_sell + 1]\n",
    "    # print(len(predictions), len(prices))\n",
    "    ofCurrency = 0\n",
    "    currentLabel = 2\n",
    "    for i in range(len(predictions)):\n",
    "        label = predictions[i]\n",
    "        # print('found label:', label)\n",
    "        if label == 1:\n",
    "            if currentLabel != 1:\n",
    "                currentLabel = 1\n",
    "                # print('change in 1: before: ', ofCurrency, money, prices[i])\n",
    "                transactions_count += 1\n",
    "                ofCurrency = money / prices[i]\n",
    "                money = 0\n",
    "                # print('change in 1: after: ', ofCurrency, money)\n",
    "        elif label == 2:\n",
    "            if currentLabel != 2:\n",
    "                currentLabel = 2\n",
    "                # print('change in 2: before: ', ofCurrency, money, prices[i])\n",
    "                transactions_count += 1\n",
    "                money = prices[i] * ofCurrency\n",
    "                ofCurrency = 0\n",
    "                # print('change in 2: after: ', ofCurrency, money)            \n",
    "    return money, ofCurrency, transactions_count"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cad8b406472b4976"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = result_df['prediction'].tolist()\n",
    "startMoney = 10000\n",
    "totalMoney, ofCurrency, transactionCount = calculate_profit(startMoney, predictions, result_df['test_price'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73b50f0f7db8bd19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if constant_transaction_fee is False, fee is a percent of the traded money (fee=0.05 for example)\n",
    "# if constant_transaction_fee is True, fee is a constant number of units in certain currency (like 1 euro) \n",
    "def strategy(labels, prices, fee, constant_transaction_fee=True):\n",
    "    i, totalTransactionLength = 0, 0\n",
    "    buyPoint, sellPoint, gain, totalGain, shareNumber, moneyTemp, maximumMoney = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    money, minimumMoney = 10000.0, 10000.0\n",
    "    maximumLost = 100.0\n",
    "    totalPercentProfit, maximumProfitPercent, maximumLostPercent, maximumGain = 0.0, 0.0, 0.0, 0.0\n",
    "    transactionCount, successTransactionCount, failedTransactionCount = 0, 0, 0\n",
    "    buyPointBAH, shareNumberBAH, moneyBAH = 10000.0, 10000.0, 10000.0\n",
    "    forceSell = False\n",
    "\n",
    "    sharpaR, prof, oneDayProf, numberOfDay, k = 0, 0, 0, 0, 0\n",
    "\n",
    "    # TODO: define non-constant transaction fee (for example a percent of the whole transaction)\n",
    "\n",
    "    print(f\"Start Capital: {money}$\")\n",
    "    while k < len(labels) - 1:\n",
    "\n",
    "        # dailyProfit[k] = 0.0\n",
    "\n",
    "        if labels[k] == 1.0:\n",
    "            buyPoint = prices[k]\n",
    "            buyPoint = buyPoint * 100\n",
    "            if constant_transaction_fee:\n",
    "                shareNumber = (money - fee) / buyPoint\n",
    "            else:\n",
    "                shareNumber = (money - money * fee) / buyPoint\n",
    "            forceSell = False\n",
    "\n",
    "            for j in range(k, len(labels) - 1):\n",
    "                sellPoint = prices[j]\n",
    "                sellPoint = sellPoint * 100\n",
    "                if constant_transaction_fee:\n",
    "                    moneyTemp = (shareNumber * sellPoint) - fee\n",
    "                else:\n",
    "                    help = shareNumber * sellPoint\n",
    "                    moneyTemp = help - help * fee\n",
    "                # stop loss %10\n",
    "                # if(money*0.95>moneyTemp){\n",
    "                # \tmoney=moneyTemp;\n",
    "                # \tforceSell=true;\n",
    "                # }\n",
    "                if labels[j] == 2.0 or forceSell:\n",
    "                    sellPoint = prices[j]\n",
    "                    sellPoint = sellPoint * 100\n",
    "                    gain = sellPoint - buyPoint\n",
    "                    if gain > 0:\n",
    "                        successTransactionCount += 1\n",
    "                    else:\n",
    "                        failedTransactionCount += 1\n",
    "                    if gain >= maximumGain:\n",
    "                        maximumGain = gain\n",
    "                        maximumProfitPercent = maximumGain / buyPoint * 100\n",
    "                    if gain <= maximumLost:\n",
    "                        maximumLost = gain\n",
    "                        maximumLostPercent = maximumLost / buyPoint * 100\n",
    "                    if constant_transaction_fee:\n",
    "                        moneyTemp = (shareNumber * sellPoint) - fee\n",
    "                    else:\n",
    "                        help = shareNumber * sellPoint\n",
    "                        moneyTemp = help - help * fee\n",
    "                    money = moneyTemp\n",
    "                    if money > maximumMoney:\n",
    "                        maximumMoney = money\n",
    "                    if money < minimumMoney:\n",
    "                        minimumMoney = money\n",
    "                    transactionCount += 1\n",
    "                    print(f'{transactionCount}.({k + 1}-{j + 1}) => {round((gain * shareNumber), 2)} Capital: {round(money, 2)}$')\n",
    "                    prof = round(round((gain * shareNumber), 2) / (money - (gain * shareNumber)), 4)\n",
    "                    numberOfDay = j - k\n",
    "                    # oneDayProf = round((prof / numberOfDay), 4)\n",
    "                    # for m in range(k + 1, j + 1):\n",
    "                    #     dailyProfit[m] = oneDayProf\n",
    "\n",
    "                    totalPercentProfit = totalPercentProfit + (gain / buyPoint)\n",
    "\n",
    "                    totalTransactionLength = totalTransactionLength + (j - k)\n",
    "                    k = j + 1\n",
    "                    totalGain = totalGain + gain\n",
    "                    break\n",
    "        k += 1\n",
    "\n",
    "    # print(\"dailyProfit[z]\")\n",
    "    # for z in range(0, dailyProfit.length):\n",
    "    #     print(f'{z}:{dailyProfit[z]}')\n",
    "    # sharpaR = findSharpaRatio(dailyProfit)\n",
    "    # \n",
    "    # print(\"Sharpa Ratio of Our System=>\" + sharpaR)\n",
    "    print(f\"Our System => totalMoney = {round(money, 2)}$\")\n",
    "\n",
    "    buyPointBAH = prices[0]\n",
    "    if constant_transaction_fee:\n",
    "        shareNumberBAH = (moneyBAH - fee) / buyPointBAH\n",
    "        moneyBAH = (prices[len(labels) - 1] * shareNumberBAH) - fee\n",
    "    else:\n",
    "        shareNumberBAH = (moneyBAH - moneyBAH * fee) / buyPointBAH\n",
    "        help = prices[len(labels) - 1] * shareNumberBAH\n",
    "        moneyBAH = help - help * fee\n",
    "        \n",
    "    print(f'BAH => totalMoney = {round(moneyBAH, 2)}$')\n",
    "\n",
    "    numberOfDays = len(labels) - 1\n",
    "    numberOfYears = numberOfDays / 365\n",
    "\n",
    "    print(f\"Our System Annualized return % => {round(((math.pow(money / 10000.0, 0.2) - 1) * 100), 2)}%\")  #5 years 0.2\n",
    "    print(\n",
    "        f\"BaH Annualized return % => {round(((math.exp(math.log(moneyBAH / 10000.0)) - 1) * 100), 2)} %\")\n",
    "    print(f\"Annualized number of transaction => {round((transactionCount), 1)} #\")\n",
    "    print(f\"Percent success of transaction => {round((successTransactionCount / transactionCount) * 100, 2)} %\")\n",
    "    print(f\"Average percent profit per transaction => {round((totalPercentProfit / transactionCount * 100), 2)} %\")\n",
    "    print(f\"Average transaction length => {totalTransactionLength / transactionCount} #\")\n",
    "    print(f\"Maximum profit percent in transaction=> {round(maximumProfitPercent, 2)} %\")\n",
    "    print(f\"Maximum loss percent in transaction=> {round(maximumLostPercent, 2)} %\")\n",
    "    print(f\"Maximum capital value=> {round(maximumMoney, 2)}$\")\n",
    "    print(f\"Minimum capital value=> {round(minimumMoney, 2)}$\")\n",
    "    print(f\"Idle Ratio %=> {round((len(labels) - totalTransactionLength / len(labels) * 100), 2)} %\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e14a0883ebb8ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = result_df['prediction'].tolist()\n",
    "prices = result_df['test_price'].tolist()\n",
    "strategy(labels, prices, 0.5, constant_transaction_fee=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebdcaf81ba2b5ff4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strategy(labels, prices, 0.005, constant_transaction_fee=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f64c9fd80d4eebd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = result_df['prediction'].tolist()\n",
    "prices = result_df['test_price'].tolist()\n",
    "strategy(labels, prices, 0.5, constant_transaction_fee=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4cc6ed07362ba6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strategy(labels, prices, 0.005, constant_transaction_fee=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3db3a17c276c2db1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = '11111#2222#33333#44444'\n",
    "position = d[::-1].find('#')\n",
    "new_string = d[::-1][position+1:][::-1]\n",
    "new_string"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4611c3cb60dc3e20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s = np.array([1,2,3])\n",
    "s = np.append(s, 4)\n",
    "s"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27620b9ead5e12ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = [[1,2,3],[4,5,6]]\n",
    "x_new = [[7,8,9],[10,11,12]]\n",
    "for xx in x_new:\n",
    "    x.append(xx)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "791fbab2cade3ffc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tulipy as ti\n",
    "import numpy as np\n",
    "r = np.array([3249.5, 3249.5,3249.5 ,3249.5, 3249.5, 3249.5, 3249.5, 3249.5, 3249.5, 3249.5,\n",
    " 3249.5, 3249.5, 3249.5 ,3249.5, 3249.5, 3249.5])\n",
    "res = ti.tema(r, period=7)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35202e33be8d0a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('prediction_tools/data_to_normalize.csv', index_col=['Datetime'])\n",
    "df_1.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24bf81f5a8fa5819"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalized_data = test_loaded_scaler(df_1)\n",
    "normalized_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a736c138cb700e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalized_data = test_loaded_scaler(data)\n",
    "# normalized_data\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd15ac9250bab6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_best_model_params(params):\n",
    "    params = sorted(params, key=lambda x: x[1][1][2]+x[1][2][1]) \n",
    "    i = 1\n",
    "    min_false_negatives_num = params[0][1][1][2]+params[0][1][2][1]\n",
    "    while params[i][1][1][2]+params[i][1][2][1] == min_false_negatives_num:\n",
    "        i += 1\n",
    "    params = sorted(params[:i], key=lambda x: -x[0]) \n",
    "    return params[0][2], params[0][3], params[0][4]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9db32fc0401530f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conf_mat1 = [[354, 225, 261],\n",
    " [134, 699, 4],\n",
    " [142, 3, 695]]\n",
    "\n",
    "conf_mat2 = [[354, 225, 261],\n",
    " [134, 699, 6],\n",
    " [142, 3, 695]]\n",
    "\n",
    "conf_mat3 = [[354, 225, 261],\n",
    " [134, 699, 5],\n",
    " [142, 3, 695]]\n",
    "\n",
    "conf_mat4 = [[354, 225, 261],\n",
    " [134, 699, 4],\n",
    " [142, 3, 695]]\n",
    "\n",
    "params = [(0.98, conf_mat1, 1, 2, 3), (0.99, conf_mat2, 0, 0, 0), (0.99, conf_mat3, 0, 0, 0), (0.97, conf_mat4, 4, 5, 6)]\n",
    "sorrrrted = get_best_model_params(params)\n",
    "print(sorrrrted)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90e8b5b39932d0c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize(data, filename):\n",
    "    scaler = MinMaxScaler((-1, 1))\n",
    "    data_to_normalize = data.drop(labels=[\"Labels\", \"Adj Close\"], axis=1)\n",
    "    columns = data_to_normalize.columns\n",
    "\n",
    "    # -212.65458552306788 109066.66666666667 (17221, 225) - min, max, shape\n",
    "    # data_to_normalize.to_csv('prediction_tools/data_to_normalize_whole.csv')\n",
    "\n",
    "    data_scaled = scaler.fit_transform(data_to_normalize.to_numpy())\n",
    "    joblib.dump(scaler, filename)\n",
    "    # index gets removed, columns are also not needed, might be removed too\n",
    "    data_scaled = pd.DataFrame(data_scaled, columns=columns)\n",
    "    data_scaled['Adj Close'] = data['Adj Close'].values\n",
    "    data_scaled['Labels'] = data['Labels'].values\n",
    "    return data_scaled\n",
    "\n",
    "def read_data_from_single_file(file_name, forex):\n",
    "    data = pd.read_csv(file_name, index_col=['Datetime'])\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    return create_data(data, forex)\n",
    "\n",
    "data = read_data_from_single_file(\"./historical_data/TCSG_minutes/2023-10-13_to_2023-11-12_TCSG.csv\", forex=False)\n",
    "\n",
    "normalized_data = normalize(data, 'prediction_tools/TCSG_minutes_scaler.sav')\n",
    "\n",
    "training_proportion = int(0.7 * len(normalized_data))\n",
    "training_set = normalized_data[:training_proportion]\n",
    "testing_set = normalized_data[training_proportion:]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6d26c728302c700"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_set.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c95f3a278700b3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8632a1cd27f9f573"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "32436f560fcdcca0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
